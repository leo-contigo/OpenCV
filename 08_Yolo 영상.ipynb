{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baea79d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c675219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 모델 구조 파일\n",
    "cfg_file = './opencv_data/yolo/yolov3.cfg'\n",
    "\n",
    "# 가중치 파일\n",
    "weights_file = './opencv_data/yolo/yolov3.weights'\n",
    "\n",
    "# 인식 가능한 사물의 이름(파일)\n",
    "class_file = './opencv_data/yolo/coco.names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b673926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.dnn.Net 000001D6391974B0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yolo 모델을 복원.\n",
    "# cv2.dnn.readNet(신경망 데이터, 가중치 데이터)\n",
    "net = cv2.dnn.readNet(weights_file, cfg_file)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87e0e29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'bicycle',\n",
       " 'car',\n",
       " 'motorbike',\n",
       " 'aeroplane',\n",
       " 'bus',\n",
       " 'train',\n",
       " 'truck',\n",
       " 'boat',\n",
       " 'traffic light',\n",
       " 'fire hydrant',\n",
       " 'stop sign',\n",
       " 'parking meter',\n",
       " 'bench',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'sheep',\n",
       " 'cow',\n",
       " 'elephant',\n",
       " 'bear',\n",
       " 'zebra',\n",
       " 'giraffe',\n",
       " 'backpack',\n",
       " 'umbrella',\n",
       " 'handbag',\n",
       " 'tie',\n",
       " 'suitcase',\n",
       " 'frisbee',\n",
       " 'skis',\n",
       " 'snowboard',\n",
       " 'sports ball',\n",
       " 'kite',\n",
       " 'baseball bat',\n",
       " 'baseball glove',\n",
       " 'skateboard',\n",
       " 'surfboard',\n",
       " 'tennis racket',\n",
       " 'bottle',\n",
       " 'wine glass',\n",
       " 'cup',\n",
       " 'fork',\n",
       " 'knife',\n",
       " 'spoon',\n",
       " 'bowl',\n",
       " 'banana',\n",
       " 'apple',\n",
       " 'sandwich',\n",
       " 'orange',\n",
       " 'broccoli',\n",
       " 'carrot',\n",
       " 'hot dog',\n",
       " 'pizza',\n",
       " 'donut',\n",
       " 'cake',\n",
       " 'chair',\n",
       " 'sofa',\n",
       " 'pottedplant',\n",
       " 'bed',\n",
       " 'diningtable',\n",
       " 'toilet',\n",
       " 'tvmonitor',\n",
       " 'laptop',\n",
       " 'mouse',\n",
       " 'remote',\n",
       " 'keyboard',\n",
       " 'cell phone',\n",
       " 'microwave',\n",
       " 'oven',\n",
       " 'toaster',\n",
       " 'sink',\n",
       " 'refrigerator',\n",
       " 'book',\n",
       " 'clock',\n",
       " 'vase',\n",
       " 'scissors',\n",
       " 'teddy bear',\n",
       " 'hair drier',\n",
       " 'toothbrush']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 물체 종류를 리스트로 추출.\n",
    "# 이미지속에 있는 물체들.. ex) 사람, 자동차, 나무 등..\n",
    "\n",
    "with open(class_file, 'rt') as fp :\n",
    "    classes = fp.readlines()\n",
    "    # \\n 제거\n",
    "    classes = [line.strip() for line in classes]\n",
    "    \n",
    "classes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "923eea24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101.94796608, 235.70840187,  59.12755141],\n",
       "       [143.22070115, 245.33652176,  61.86591291],\n",
       "       [222.01429184, 195.12178967,   5.03792529],\n",
       "       [ 63.02576773,  69.30901786,  20.29034193],\n",
       "       [159.8322874 ,  51.93713859, 117.12739412],\n",
       "       [  5.78058367,  16.26709533, 245.75208517],\n",
       "       [141.58649718, 251.31314898, 113.32560575],\n",
       "       [163.18775742, 105.41093264, 195.88889444],\n",
       "       [ 62.32582653, 100.74530822, 127.00476294],\n",
       "       [202.36897259, 178.01973735, 184.82526816],\n",
       "       [176.70097887, 239.72039562, 144.88027085],\n",
       "       [ 18.20968658,  45.11383301,  70.07304014],\n",
       "       [ 67.18460265,  52.97645867,  78.57847074],\n",
       "       [ 28.70603412,  64.43976224, 233.9406463 ],\n",
       "       [ 23.30409159, 175.46496336, 174.18164183],\n",
       "       [173.17209822,  84.47690389,  32.57344417],\n",
       "       [157.47435184, 111.46035087, 137.04720376],\n",
       "       [108.64367479, 196.642512  ,  17.03235471],\n",
       "       [ 11.30025059,  97.9862519 ,  59.43663759],\n",
       "       [ 19.80489162, 123.45038249, 115.43531171],\n",
       "       [100.3423423 , 187.25157889,   7.89739341],\n",
       "       [ 45.38266491,  34.69438211, 196.72709479],\n",
       "       [138.73778402, 145.67723443, 194.65867456],\n",
       "       [ 46.08138373,  58.99446118,  15.09522157],\n",
       "       [ 27.03461034, 118.11314416, 196.86868898],\n",
       "       [ 48.19852285, 126.77268103, 234.0319904 ],\n",
       "       [ 61.16884865, 197.23215004, 161.00899849],\n",
       "       [254.57773444, 237.71290548,  78.63451609],\n",
       "       [248.37030061,  65.92467641, 132.25015481],\n",
       "       [ 66.70658984, 233.64609979,   7.58302167],\n",
       "       [ 92.76966244, 121.45650449,  35.98643648],\n",
       "       [234.32046073,  14.41363942, 156.60789668],\n",
       "       [129.12113204,   6.19481763, 139.61816498],\n",
       "       [157.51974165, 137.42404274,  49.06243855],\n",
       "       [158.48648524,  64.07989164,  27.92603268],\n",
       "       [238.79468032,  77.15379499,  66.0337427 ],\n",
       "       [200.33231645,  76.91074643,  83.19367799],\n",
       "       [191.04190828, 225.56369251,  35.79531151],\n",
       "       [  1.91319226,  55.29561296, 141.10186501],\n",
       "       [ 29.80555409,  17.48788593, 141.05090234],\n",
       "       [101.38998082,  35.50966651,  49.71833381],\n",
       "       [ 63.50737456, 247.66544106, 218.70521483],\n",
       "       [236.80355651, 126.26044772, 230.46576488],\n",
       "       [139.20206437, 205.66224391, 115.07283855],\n",
       "       [217.20940567,  87.0656415 ,  63.80332215],\n",
       "       [ 88.11406403, 165.82815264, 104.8961652 ],\n",
       "       [233.50570639, 131.91712682,  49.91449829],\n",
       "       [244.17610991, 235.73830104, 213.76008833],\n",
       "       [250.73764591, 184.53556737,  60.04650157],\n",
       "       [228.5448209 , 225.54653301, 120.14520384],\n",
       "       [193.00743648,  54.92331894,  36.01672501],\n",
       "       [ 49.11597485, 155.06008436, 177.71148177],\n",
       "       [232.73819989, 132.5304258 , 221.86211555],\n",
       "       [244.07312368, 219.10824313, 225.28857478],\n",
       "       [199.07229848, 120.9177606 , 132.33293164],\n",
       "       [115.41235238, 216.1516828 ,  65.21969968],\n",
       "       [ 39.97230862, 126.88124676, 105.33870634],\n",
       "       [206.38839804, 110.49644064,  44.79334239],\n",
       "       [197.81873641, 125.62659158, 165.25216412],\n",
       "       [211.85713614,  32.7941778 , 233.22400541],\n",
       "       [110.99655425,  68.23831688,   0.86889409],\n",
       "       [ 46.81183333, 163.94886385, 203.44310206],\n",
       "       [ 48.65923805, 126.64375162, 209.35153993],\n",
       "       [162.05546569, 150.73776292,  37.38201168],\n",
       "       [ 49.23593409, 109.97294722, 153.50075363],\n",
       "       [  9.70528755, 168.78437601,  15.90869161],\n",
       "       [235.65872359,  48.80643683,  62.91064821],\n",
       "       [ 81.71094833, 164.25254041, 213.81038033],\n",
       "       [233.98041404, 184.51759916, 208.38101858],\n",
       "       [  0.94605568, 110.31743156, 105.16811066],\n",
       "       [ 87.21564128, 202.00687592, 253.94231129],\n",
       "       [ 87.01904236,  10.88782076,  37.64095219],\n",
       "       [241.30676008,  69.48079107,  65.24859098],\n",
       "       [180.58792559, 124.93730513,  12.4546401 ],\n",
       "       [236.33623999,  15.98871082, 222.64012938],\n",
       "       [148.8176301 , 140.70159225, 230.56948709],\n",
       "       [ 45.7772949 , 116.39097029, 252.84919148],\n",
       "       [ 78.55728357, 244.76703602,  99.34278932],\n",
       "       [ 32.02338715, 249.38650588,  50.83657512],\n",
       "       [112.92381499,  75.26717207, 231.31868652]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 물체를 의미하는(가리키는) 색상을 랜덤하게 생성.\n",
    "# 0 ~ 255 사이 \n",
    "# r, g, b\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad91d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 영상을 가져온다.\n",
    "cap = cv2.VideoCapture('./opencv_data/video/yolo_01.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6f15b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엔터키를 누를때 까지 반복.\n",
    "while cv2.waitKey(33) < 0 :\n",
    "    # 현재 프레임을 가져옴.\n",
    "    ret, img = cap.read()\n",
    "    # 더이상 가져올 것이 없다면 (끝까지 갔을 경우) 종료\n",
    "    if img is None :\n",
    "        break\n",
    "#   ------------↓ yolo 사진 내용과 동일 ---------------      \n",
    "    # 이미지 세로, 가로, 채널\n",
    "    height, width, channel = img.shape\n",
    "    \n",
    "    # 이미지 크기 조정. cv2.resize(원본데이터, (세로,가로))\n",
    "    # 16*16 부터 16 배수로 설정.\n",
    "    a1 = cv2.resize(img, (416,416))\n",
    "    \n",
    "    # 2진 데이터로 변환.\n",
    "    # 0.00392(기준) - 임계값. 이 값보다 크면 1, 작으면 0으로 변환.\n",
    "    blob = cv2.dnn.blobFromImage(a1, 0.00392, (416, 416), (0, 0, 0))\n",
    "    \n",
    "    # 예측 전 신경망 구조를 살핌.\n",
    "    # 모델의 정보를 확인. 은닉층들의 이름을 가져옴.\n",
    "    # 이 부분은 생략 가능\n",
    "    \n",
    "    # 출력층 이름.\n",
    "    output_layers = net.getUnconnectedOutLayersNames()\n",
    "    # 결론 : 신경망이 3개.\n",
    "    \n",
    "    # 이미지 데이터를 모델에 셋팅.\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    # 물체를 검출. 출력층이 3개이기때문에 ndarray도 3개 \n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "\n",
    "    # 예측된 결과를 담을 리스트\n",
    "    class_id_list = []\n",
    "    # 예측 정확도\n",
    "    confidence_list = []\n",
    "    # 인지된 사물의 영역\n",
    "    box_list = []\n",
    "\n",
    "    # 확률의 임계값\n",
    "    # 이 확률 이상인 것만 결과에 담는다.\n",
    "    # 0.1 ~ 2 정도로 잡아도 충분함.\n",
    "    confidence_limit = 0.5\n",
    "\n",
    "    for out in outs :\n",
    "        # 현재의 출력층이 검출한 물체의 수 만큼 반복.\n",
    "        for detection in out :\n",
    "            # 원핫 인코딩되어 있는 확률값만 가져온다.\n",
    "            score_list = detection[5:]\n",
    "            # 확률이 가장 높은 물체 값을 가져온다.\n",
    "            class_id = np.argmax(score_list)\n",
    "            # 확률을 가져온다.\n",
    "            confidence = score_list[class_id]\n",
    "    #         print(classes[class_id] , score_list[class_id])\n",
    "\n",
    "            # 확률이 혹률 임계값 이상인 것만 처리.\n",
    "            if confidence >= confidence_limit:\n",
    "     \n",
    "                # 물체의 좌표를 계산.\n",
    "                # 예측결과에서 앞 4개는 중심점 x 비율, 중심점 y비율, 가로비율, 세로비율\n",
    "                # 원본 이미지로 환산\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "\n",
    "                # 가로길이\n",
    "                w = int(detection[2] * width)\n",
    "                # 세로길이\n",
    "                h = int(detection[3] * height)\n",
    "                # 좌측 상단 x\n",
    "                x = int(center_x - w / 2)\n",
    "                # 좌측 상단 y\n",
    "                y = int(center_y - h / 2)        \n",
    "\n",
    "                # 담는다.\n",
    "                box_list.append([x, y, w, h])\n",
    "                confidence_list.append(float(confidence))\n",
    "                class_id_list.append(class_id)\n",
    "\n",
    "    # IoU : 두 면적이 중첩되는 영역의 넓이를 두 면적의 함친 총 면적으로 나눈 값\n",
    "    # 두 면적이 얼마나 중첩되어 있는지 평가할 수 있는 지표\n",
    "    # 0 ~ 1 사이가 나오며 값이 클수록 중첩된 부분이 많다고 평가.\n",
    "\n",
    "    # NMS : IoU 방식으로 면적을 평가하고 중첩이 많이 되었다고 판단되는 영역을 제거하는 방식.\n",
    "    # IoU 방식으로 평가하여 중첩이 많이 되었다고 판단되는 영역을 모두 아우를수 있는 영역을 만들어 냄.\n",
    "    # cv2.dnn.NMSBoxes( 사물영역, 예측정확도, 확률임계값, 확인하지않고 버릴 영역의 확률값(확률임계값보다 낮게))\n",
    "\n",
    "    # 결과는 인식한 사물의 index 번호\n",
    "    indexes = cv2.dnn.NMSBoxes(box_list, confidence_list, confidence_limit, 0.4)\n",
    "    \n",
    "    # 검출된 물체의 수 만큼 반복.\n",
    "\n",
    "    for i in range(len(box_list)) :\n",
    "        # NMS를 통해 추출한 영역만 표시.\n",
    "        if i in indexes : \n",
    "\n",
    "            # 좌표값을 추출.\n",
    "            x, y, w, h = box_list[i]\n",
    "            # 이름.\n",
    "            label = str(classes[class_id_list[i]])\n",
    "            # 색상.\n",
    "            color = colors[class_id_list[i]]\n",
    "\n",
    "            # 네모를 그린다.\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), color, 2)\n",
    "            # 이름을 표시. cv2.FONT_HERSHEY_PLAIN(폰트), 크기, 색상, 두께\n",
    "            cv2.putText(img, label, (x, y-30), cv2.FONT_HERSHEY_PLAIN, 3, color, 3)\n",
    "\n",
    "    cv2.imshow('Object Detection', img)\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5260dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99837e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
